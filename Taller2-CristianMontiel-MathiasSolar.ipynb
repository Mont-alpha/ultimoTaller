{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR3ZLnj7LuL5"
      },
      "source": [
        "<head><b><center><h1>TALLER N°2 DE CIENCIA DE DATOS</h1></center>\n",
        "    <center>Arbol de Clasificacion</center></b>\n",
        "</head>\n",
        "\n",
        "<h3>Integrantes:</h3>\n",
        "<ul>\n",
        "    <li>Cristian Montiel</li>\n",
        "    <li>Mathias Solar</li>\n",
        "</ul>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLmXiFxJLuL7"
      },
      "source": [
        "<h3><b>Actividad 1: Organización del Set de Datos</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KmIzpt3LuL8"
      },
      "source": [
        "En la actividad 1, se ha optado por utilizar la estrategia de validación cruzada para la evaluación de los parámetros de los modelos de clasificación. Esta elección se fundamenta en diversas razones que contribuyen a una evaluación más robusta y confiable del rendimiento del modelo.\n",
        "\n",
        "En primer lugar, la validación cruzada permite una evaluación más robusta al utilizar múltiples particiones de datos para entrenamiento y prueba. Esto reduce la posibilidad de sesgo en el rendimiento del modelo causado por una única división de datos. Además, al realizar k entrenamientos y pruebas con diferentes conjuntos de datos, se minimiza el impacto de la variabilidad en los datos, siendo crucial para conjuntos de datos limitados o cuando se busca la generalización del modelo.\n",
        "\n",
        "Además, la validación cruzada garantiza que cada observación en el conjunto de datos tenga la oportunidad de formar parte del conjunto de prueba en al menos una iteración, asegurando la consideración de todas las instancias en la evaluación del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate, train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Leer el archivo de muestra\n",
        "with open(\"muestra_taller_2_entrenamiento.csv\", \"r\") as file:\n",
        "    muestra = [line.strip().split(\",\") for line in file.readlines()]\n",
        "\n",
        "# Convertir los valores objetivo a 0 o 1\n",
        "muestra = np.array(muestra, dtype='object')\n",
        "\n",
        "muestra[:, -1] = np.where(muestra[:, -1] == \"0.0\", 0, 1)  #(condicion , aplicacion si se cumple, else)\n",
        "\n",
        "# Obtener valores de características y objetivo\n",
        "X = muestra[:, :-1].astype(float) #selecciona todas las columnas de cada fila pero no la ultima columna\n",
        "y = muestra[:, -1].astype(float) #selecciona la ultima columna de cada fila\n",
        "\n",
        "# Instanciar el clasificador con la seed 1234\n",
        "clf = DecisionTreeClassifier(random_state=1234)\n",
        "\n",
        "# Usar 5 carpetas de validación cruzada para evaluar el clasificador\n",
        "cv_results = cross_validate(clf, X, y, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmJ6rl1AM8Jo"
      },
      "source": [
        "<h3><b>Actividad 2: : Selección de criterio de evaluación</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY42dy74NAa4"
      },
      "source": [
        "Para el desarrallo de la actividad , nuestra decision consitio en la eleccion de la metrica de evaluacion correspondiente a <b>F1 score</b>. Su eleccion se debe a la tasa de exito (vease a encontrar los casos de fraude) sin que hubiesen casos fallidos (encontrar casos normales),ademas de ser equilibrado a la ahora de mostrar casos que son falsamente exitosos y fallidos a comparacion de tecnicas como recall (mayor cantidad de casos de falsos exitosos).\n",
        "\n",
        "Para poder hacer uso de dicha metrica , se necesito de la yuda de la libreria sklearn.metrics, que ademas de proporcionar la metrica necesaria tambien incluye otras como recall o precision.La funcion que se proporciona se denomina f1_score.\n",
        "\n",
        "Esta métrica la utilizaremos en la función que realiza la busqueda de la mejor grilla, además de calcularla individualmente para determinar si nuestro modelo de clasificación es lo suficientemente bueno o no. El que un modelo sea bueno o malo se define como la capacidad para identificar transferencias fraudulentas como legítimas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros:  {'splitter': 'best', 'random_state': 99, 'min_samples_split': 2, 'max_depth': 4, 'criterion': 'gini'}\n",
            "Mejor puntaje:  0.922483289755095\n",
            "F1 Score: 0.926\n",
            "Informe de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      1903\n",
            "         1.0       0.98      0.88      0.93        72\n",
            "\n",
            "    accuracy                           0.99      1975\n",
            "   macro avg       0.99      0.94      0.96      1975\n",
            "weighted avg       0.99      0.99      0.99      1975\n",
            "\n",
            "Accuracy: 0.995\n",
            "Precision: 0.984\n",
            "Recall: 0.875\n",
            "F1 Score: 0.926\n",
            "Matriz de confusión:\n",
            "[[1902    1]\n",
            " [   9   63]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# Definir los parámetros de búsqueda de la grilla\n",
        "param_grid = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, None],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'min_samples_split': [2, 3, 4, 5, 10],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'random_state':[123,99,43,12]\n",
        "}\n",
        "\n",
        "# Instanciar el clasificador\n",
        "clf = DecisionTreeClassifier(random_state =123)\n",
        "\n",
        "# Realizar búsqueda de grilla con validación cruzada de 5 carpetas\n",
        "random_search = RandomizedSearchCV(clf, param_grid, scoring='f1', n_iter=50, cv=5, random_state=1234)\n",
        "\n",
        "# Ajustar el modelo con búsqueda de grilla\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir mejores parámetros y mejor puntaje\n",
        "print(\"Mejores parámetros: \", random_search.best_params_)\n",
        "print(\"Mejor puntaje: \", random_search.best_score_)\n",
        "\n",
        "# Crear el clasificador con los mejores parámetros\n",
        "best_params = random_search.best_params_\n",
        "clf = DecisionTreeClassifier(random_state=random_search.best_params_['random_state'],\n",
        "                            max_depth=random_search.best_params_['max_depth'],\n",
        "                            criterion=random_search.best_params_['criterion'],\n",
        "                            min_samples_split=random_search.best_params_['min_samples_split'],\n",
        "                            splitter=random_search.best_params_['splitter'])\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predecir en el conjunto de prueba\n",
        "y_hat = clf.predict(X_test)\n",
        "\n",
        "#Se calcula el f1_score para nuestro módelo\n",
        "f1 = f1_score(y_test, y_hat)\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "\n",
        "print(\"Informe de clasificación:\")\n",
        "print(classification_report(y_test, y_hat))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "precision = precision_score(y_test, y_hat)\n",
        "recall = recall_score(y_test, y_hat)\n",
        "f1 = f1_score(y_test, y_hat)\n",
        "confusion_mat = confusion_matrix(y_test, y_hat)\n",
        "\n",
        "# Imprimir los mejores parámetros y las métricas de evaluación\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3><b>Actividad 3: Selección de modelos e hiper-parámetros</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se seleccionaron dos modelos adecuados para abordar el problema de detección de fraudes: modelo de árboles de decisión y el modelo no supervisado de clustering. \n",
        "Se escogio el arbol de claisificacion porque su versatilidad y facilidad de interpretación los hacen ideales. Dos parámetros clave a ajustar son la profundidad del árbol, que controla su complejidad, y la métrica de selección de características, como la entropia o la indice de Gini.\n",
        "\n",
        "tambien el aprendizaje supervisado ya que estos redicen una variable objetivo a partir de un conjunto de datos de características. Son versátiles y se adaptan a diversas aplicaciones, incluida la detección de fraudes. Los parámetros ajustables incluyen el método de optimización, como el descenso del gradiente, y el criterio de parada, que determina cuándo se detiene el ajuste del modelo.\n",
        "\n",
        "para la busqueda del mejor clasificador La estrategia elegida es la validación cruzada con 5 carpetas para evaluar el rendimiento del clasificador en un conjunto independiente. Se realizarán dos experimentos para cada tipo de modelo:\n",
        "\n",
        "Árbol de Decisión (Experimento 1): Profundidad del árbol de 5 niveles y métrica de selección de características de información mutua.\n",
        "\n",
        "Árbol de Decisión (Experimento 2): Profundidad del árbol de 10 niveles y métrica de selección de características de ganancia de Gini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experimento 1: Árbol de decisión con profundidad de 5 niveles y métrica de selección de características de la información mutua\n",
            "{'fit_time': array([0.2698791 , 0.27262259, 0.28029323, 0.27657747, 0.27245879]), 'score_time': array([0.00100136, 0.00100064, 0.00050354, 0.00200176, 0.00100303]), 'test_score': array([0.99493671, 0.9964557 , 0.99594937, 0.98784195, 0.9929078 ])}\n",
            "Características seleccionadas después de aplicar SelectFromModel:\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import mutual_info_classif as info_mutual #es una funcion\n",
        "\n",
        "# Leer el archivo de muestra\n",
        "with open(\"muestra_taller_2_entrenamiento.csv\", \"r\") as file:\n",
        "    muestra = [line.strip().split(\",\") for line in file.readlines()]\n",
        "\n",
        "# Convertir los valores objetivo a 0 o 1\n",
        "muestra = np.array(muestra, dtype='object')\n",
        "muestra[:, -1] = np.where(muestra[:, -1] == \"0.0\", 0, 1)\n",
        "\n",
        "# Obtener valores de características y objetivo\n",
        "X = muestra[:, :-1].astype(float)\n",
        "y = muestra[:, -1].astype(float)\n",
        "\n",
        "# Experimento 1: Árbol de decisión con profundidad de 5 niveles y métrica de criterio entropy\n",
        "clf_svm = svm.SVC(kernel='poly') \n",
        "clf_svm.fit(X_train, y_train)\n",
        "y_predicho = clf_svm.predict(X_test)\n",
        "precision_svm = accuracy_score(y_test, y_predicho)\n",
        "print(\"Exactitud del clasificador SVM: {:.2f}\".format(precision_svm))\n",
        "\n",
        "clf_1 = DecisionTreeClassifier(max_depth=5, criterion=\"entropy\") #-> criterion =>{'log_loss', 'gini', 'entropy'}\n",
        "cv_results_1 = cross_validate(clf_1, X, y, cv=5)\n",
        "\n",
        "# Utilizar SelectFromModel para aplicar la métrica de selección de características\n",
        "selector = SelectFromModel(clf_1)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Imprimir los resultados de los experimentos\n",
        "print(\"Experimento 1: Árbol de decisión con profundidad de 5 niveles y métrica de selección de características de la información mutua\")\n",
        "print(cv_results_1)\n",
        "print(\"Características seleccionadas después de aplicar SelectFromModel:\")\n",
        "print(X_selected.shape[1])  # Imprimir la cantidad de características seleccionadas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3><b>Actividad 4: Aplicación a nuevos casos</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introducir texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import csv\n",
        "\n",
        "# Leer el archivo de nuevos casos\n",
        "datos_nuevos = []\n",
        "with open('muestra_taller_2_evaluación.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        datos_nuevos.append(row)\n",
        "\n",
        "# Eliminar filas con valores faltantes\n",
        "datos_nuevos = np.array(datos_nuevos, dtype='object')\n",
        "datos_nuevos = datos_nuevos[~np.any(datos_nuevos == '', axis=1)]\n",
        "\n",
        "# Obtener características de los nuevos casos\n",
        "X_nuevos = datos_nuevos.astype(float)\n",
        "\n",
        "# Cargar tus datos de entrenamiento (asegúrate de cambiar 'nombre_del_archivo.csv' por el nombre correcto)\n",
        "datos_entrenamiento = np.loadtxt('muestra_taller_2_entrenamiento.csv', delimiter=',', skiprows=1)\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X_train = datos_entrenamiento[:, :-1]  # Todas las columnas excepto la última\n",
        "y_train = datos_entrenamiento[:, -1]   # Última columna\n",
        "\n",
        "# Cargar el modelo mejor encontrado\n",
        "mejor_modelo = DecisionTreeClassifier(random_state=123, max_depth=5, criterion='entropy', min_samples_split=2, splitter='best')\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento completos\n",
        "mejor_modelo.fit(X_train, y_train)\n",
        "\n",
        "# Obtener las probabilidades de predicción\n",
        "y_hat = mejor_modelo.predict_proba(X_nuevos)\n",
        "\n",
        "# Seleccionar 300 casos con mayor probabilidad de ser fraude\n",
        "indices_inspeccion = np.argsort(y_hat[:, 1])[::-1][:500]\n",
        "\n",
        "# Generar el archivo \"inspeccionar.csv\"\n",
        "with open('inspeccionar.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for index in indices_inspeccion:\n",
        "        writer.writerow([index])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
